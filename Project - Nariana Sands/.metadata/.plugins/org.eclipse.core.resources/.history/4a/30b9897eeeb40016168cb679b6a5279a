import java.util.List;
import java.util.Properties;
import java.util.regex.Pattern;

import edu.stanford.nlp.ling.CoreAnnotations.PartOfSpeechAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.SentencesAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TokensAnnotation;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.util.CoreMap;

public class POS {
	public static void main(String [] args){
		String featureRequest = args[0]; //Your feature request
		String q1 = args[1]; //question 1
		String answer1 = args[2]; //answer 1
		String q2 = args[3]; //question 3
		String a2 = args[4]; //answer 2
		
		int s1, s2, s3 = 0;
		
		
		Properties props = new Properties();
		props.setProperty("ner.useSUTime", "false");
		props.setProperty("annotators", " tokenize, ssplit, pos, lemma, ner, parse, dcoref ");
		StanfordCoreNLP pipeline = new StanfordCoreNLP(props);

		Annotation document = new Annotation(featureRequest);
		pipeline.annotate(document);
		List<CoreMap> sentences = document.get(SentencesAnnotation.class);
		for (CoreMap sentence : sentences) {
			List<CoreLabel> tokens = sentence.get(TokensAnnotation.class);
			for (CoreLabel token : tokens) {
				String pos = token.get(PartOfSpeechAnnotation.class);//Get POS of each word
				System.out.print(token + "/" + pos + " ");
			}
		}
	}
	
	public static int s1(String featureRequest, String answer){
		int s1 = -1; //error if it remains -1
		if(Pattern.compile(Pattern.quote(answer), Pattern.CASE_INSENSITIVE).matcher(featureRequest).find())
			s1 = 1; //should be 1 for every sentence
		return s1;
	}
	
	public static int s2(String featureRequest){
		int s2 = -1;
		return s2;
	}
}